{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import baseRNN\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "NUM_SAMPLES = 1000\n",
    "imdbDataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "embeddingsFilepath = '/Users/josep/Desktop/Self/Learning/NLP/RNN/data/glove.6B.300d.txt'\n",
    "\n",
    "# helper functions\n",
    "def read_corpus(dataset):\n",
    "    files = dataset[\"train\"][\"text\"][:NUM_SAMPLES]\n",
    "    return [[START_TOKEN] + [re.sub(r'[^\\w]', '', w.lower()) for w in f.split(\" \")] + [END_TOKEN] for f in files]\n",
    "\n",
    "\n",
    "def embedding_for_vocab(filepath, words, dimensions):\n",
    "    vocab_size = len(words)\n",
    "    embeddings = np.zeros((vocab_size, dimensions))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in words.keys():\n",
    "                index = words[word]\n",
    "                embeddings[index] = np.array(vector)[:dimensions]\n",
    "    return embeddings\n",
    "\n",
    "imdbCorpus = read_corpus(imdbDataset)\n",
    "\n",
    "corpusWords = [y for x in imdbCorpus for y in x]\n",
    "corpusWords = list(set(corpusWords))\n",
    "word2ind={}\n",
    "for i in range(len(corpusWords)+1):\n",
    "    word2ind[corpusWords[i-1]] = i\n",
    "word2ind['<PAD>'] = 0\n",
    "embeddings = embedding_for_vocab(embeddingsFilepath, word2ind, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3946, 17881,  8953, 17881,  3139, 10843,  8068, 18464, 10898,\n",
       "       16902,  4379,  4857, 16724, 13238,  5860,  7178, 10041,  1127,\n",
       "        4013,  1127,  1482, 17129,  9803,   148,  1600, 17881, 12035,\n",
       "       17269,  7178, 11409, 17129,  1127,  1482,  3369,   212,   462,\n",
       "        3601, 16960,  1127, 14648, 17404,  1581,   534,  2862,  6372,\n",
       "       18434, 11110,   279,  6285,  4857,  1646,  7798,   885, 17881,\n",
       "          56,  6365,  1581,  2609,  2862, 13620, 17580, 16919, 13238,\n",
       "        1211, 12799, 10632, 10894,   279, 15168,  9555, 11537, 17829,\n",
       "        7855,  4789,  3766, 12841,  1581, 14062,  7212,  6023,  1966,\n",
       "       17378,  9415,   148, 18814,  6023, 12841,  1581, 12356,  4080,\n",
       "       18166,  1581, 12787, 10717, 12681,  4857, 14209, 11669,  9116,\n",
       "       13238,   652,  4232,   597, 17378,  6264,  9319,  9504,  3793,\n",
       "        6395, 13238,  4512,  4595,  7501,  5523,  9504,   148, 13238,\n",
       "        7269,  1257,   148, 16383, 11495,  5924,  7501, 15477,  1893,\n",
       "        4857, 17253, 17378, 11837,  4997, 11669,  5089,  6023,  9606,\n",
       "        6984,  6600,  4080, 11537, 13100, 18313,  7501,  7678,   340,\n",
       "       16919,  9116,  5899, 16816, 17378, 17881,  3139, 10843, 12799,\n",
       "        7178, 11779,  7857,  6084,  2862,  1482,  7798, 15392,    56,\n",
       "       13238,  6984,  7501,  1001, 18066, 14912,  1425,  7501,  5002,\n",
       "       16383,  7978,  1236, 14827, 15340,  6272,  6875, 10717, 17044,\n",
       "        4916,   255,  1727, 18464,   809, 15859,  5412,  1127,  3980,\n",
       "         148, 11115,  6984,  7501,  1001, 14912,   279, 12217,  9722,\n",
       "         148,  9555,  6015,  7978, 12009,  4365, 16735, 11837,  2675,\n",
       "        1581,  1270,  9188,  8863, 16261,  9841,  6365,  6984, 18066,\n",
       "         148,  7309, 13168, 16919, 17881,  2760,  6456, 13238,  2634,\n",
       "       13620, 13238,  9021,  7178,  3815,  6984,  4150,   148, 13238,\n",
       "        6142, 12799,  4150, 13620,  3609,  8312,  4584, 11685, 15471,\n",
       "        1581,  2824,  4063,  7501, 18322, 18521,  1581,  1960,  4150,\n",
       "         148, 15392,  5302,   148,  5488, 17881,  3139, 10843, 12799,\n",
       "         279,  1270,  6142, 13620, 14581, 10274,  1581, 15310, 13238,\n",
       "       12762,  7501,  9357, 17103, 11528, 14260,  4857,  9555,  6015,\n",
       "       16166,    56,  2862,  6142,  1322,  5468, 14289,  4857,   279,\n",
       "        1211,  4205])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testText = np.array(imdbCorpus[0])\n",
    "mapper = np.vectorize(word2ind.get)\n",
    "result = mapper(testText)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRNN = baseRNN.neuralNet(embeddings=embeddings, word2ind=word2ind, outputActivation='softmax',\n",
    "                            hiddenLayerShapes=[100,100,100], hiddenLayerActivations=['relu', 'relu', 'relu'],\n",
    "                            lossFunction='crossEntropyLoss', learningRate=.001, epochs=1, batchSize=2,\n",
    "                            adam=True, clipVal=1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overfitCorpus = [imdbCorpus[0][0:20]] * 10\n",
    "# overfitCorpus = [overfitCorpus, overfitCorpus]\n",
    "testCorpus = imdbCorpus[:2]\n",
    "len(testCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.547549525405584\n",
      "********************************************\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,19042) (19042,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m testRNN\u001b[38;5;241m.\u001b[39mtrainBatch(testCorpus)\n",
      "File \u001b[1;32mc:\\Users\\josep\\Desktop\\Self\\Learning\\NLP\\RNN\\baseRNN.py:309\u001b[0m, in \u001b[0;36mtrainBatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\josep\\Desktop\\Self\\Learning\\NLP\\RNN\\baseRNN.py:243\u001b[0m, in \u001b[0;36mneuralNet.backwardPass\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# adam\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m currLayer\u001b[38;5;241m.\u001b[39madam:\n\u001b[1;32m--> 243\u001b[0m     currLayer\u001b[38;5;241m.\u001b[39mlayerWeightUpdates, currLayer\u001b[38;5;241m.\u001b[39mtimeWeightUpdates, currLayer\u001b[38;5;241m.\u001b[39mbiasUpdates \u001b[38;5;241m=\u001b[39m currLayer\u001b[38;5;241m.\u001b[39mupdateAdam(\n\u001b[0;32m    244\u001b[0m         currLayer\u001b[38;5;241m.\u001b[39mlayerWeightUpdates, currLayer\u001b[38;5;241m.\u001b[39mtimeWeightUpdates, currLayer\u001b[38;5;241m.\u001b[39mbiasUpdates)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# updates\u001b[39;00m\n\u001b[0;32m    247\u001b[0m currLayer\u001b[38;5;241m.\u001b[39mlayerWeights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearningRate\u001b[38;5;241m*\u001b[39mcurrLayer\u001b[38;5;241m.\u001b[39mlayerWeightUpdates\n",
      "File \u001b[1;32mc:\\Users\\josep\\Desktop\\Self\\Learning\\NLP\\RNN\\neuronLayer.py:56\u001b[0m, in \u001b[0;36mupdateAdam\u001b[1;34m(self, dLdLayerWeights, dLdTimeWeights, dLdBias)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdLayerWeights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdLayerWeights \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta1)\u001b[38;5;241m*\u001b[39mdLdLayerWeights \u001b[38;5;66;03m# momentum stored\u001b[39;00m\n\u001b[0;32m     55\u001b[0m mdLayerWeightsHat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdLayerWeights \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mb1T) \u001b[38;5;66;03m# momentum correction\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvdLayerWeights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta2\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvdLayerWeights \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta2)\u001b[38;5;241m*\u001b[39m(dLdLayerWeights\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# RMSProp stored\u001b[39;00m\n\u001b[0;32m     57\u001b[0m vdLayerWeightsHat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvdLayerWeights \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mb2T) \u001b[38;5;66;03m# RMSProp correction\u001b[39;00m\n\u001b[0;32m     58\u001b[0m newdLdLayerWeights \u001b[38;5;241m=\u001b[39m mdLayerWeightsHat \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt(vdLayerWeightsHat)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon) \u001b[38;5;66;03m# Adam\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,19042) (19042,100) "
     ]
    }
   ],
   "source": [
    "testRNN.trainBatch(testCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', 'because', 'of', 'all', 'the', 'controversy', 'it', 'it', 'it', 'it', 'it']\n"
     ]
    }
   ],
   "source": [
    "input = ['<START>', 'my', 'name', 'is', 'video', 'what', 'is', 'yours']\n",
    "\n",
    "input = ['<START>', 'because', 'of', 'all', 'the', 'controversy']\n",
    "\n",
    "output = testRNN.generateOutput(input, 5)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it'], ['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it']]\n"
     ]
    }
   ],
   "source": [
    "print(overfitCorpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
